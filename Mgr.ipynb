{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/zakrzewki/pracaMgr/blob/master/Mgr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8PnUCq9uBE11",
    "colab_type": "text"
   },
   "source": [
    "First of all, take fresh data from repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "ArDEjtRbXsuH",
    "colab_type": "code",
    "outputId": "1cb5d685-e023-4226-c264-da6b0e188d38",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'pracaMgr'...\n",
      "remote: Enumerating objects: 58, done.\u001b[K\n",
      "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
      "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
      "remote: Total 11390 (delta 34), reused 40 (delta 17), pack-reused 11332\u001b[K\n",
      "Receiving objects: 100% (11390/11390), 93.98 MiB | 7.54 MiB/s, done.\n",
      "Resolving deltas: 100% (3072/3072), done.\n",
      "Checking out files: 100% (8833/8833), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/zakrzewki/pracaMgr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXW6UfqiCekO",
    "colab_type": "text"
   },
   "source": [
    "**Connect to Google Drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "nINC164BIfbd",
    "colab_type": "code",
    "outputId": "15462629-d6ec-4607-c4bd-fe8117f52288",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to mount your Google Drive.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQoduFgAeIb0",
    "colab_type": "text"
   },
   "source": [
    "Fast checker if connection and exporting files to Google Drive are working correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "fccptudEN5ya",
    "colab_type": "code",
    "outputId": "4d736418-941d-4b1b-e18c-1bdafb702694",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following path exists, file was successfully exported\n"
     ]
    }
   ],
   "source": [
    "!python3 /content/pracaMgr/GoogleDriveChecker.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztHQtSXeBJjY",
    "colab_type": "text"
   },
   "source": [
    "**Downgrade keras** (`train_frcnn.py` throws error when it's 2.2.4 version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "0BvRNAzBXbov",
    "colab_type": "code",
    "outputId": "004de53c-728f-46fd-fed3-804ac7cc45d6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.1.6\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/e8/eaff7a09349ae9bd40d3ebaf028b49f5e2392c771f294910f75bb608b241/Keras-2.1.6-py2.py3-none-any.whl (339kB)\n",
      "\u001b[K     |████████████████████████████████| 348kB 34.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.6) (1.16.4)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.6) (1.12.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.6) (1.3.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.1.6) (3.13)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.1.6) (2.8.0)\n",
      "Installing collected packages: keras\n",
      "  Found existing installation: Keras 2.2.4\n",
      "    Uninstalling Keras-2.2.4:\n",
      "      Successfully uninstalled Keras-2.2.4\n",
      "Successfully installed keras-2.1.6\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.1.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYAe_mpQBMTv",
    "colab_type": "text"
   },
   "source": [
    "**Create a connection with Kaggle DB for downloading data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "LO3epWvqW9hd",
    "colab_type": "code",
    "outputId": "c49dc025-8f51-486c-d6b9-0766434e3acd",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/content/.kaggle’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir /content/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "JHcmirfoXJkt",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "token = {\"username\":\"michzak\",\"key\":\"558c3de4322bd2128047049c6ea44e42\"}\n",
    "\n",
    "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
    "    json.dump(token, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "G_i8_ipLXL3B",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "qCcr83TlXMAp",
    "colab_type": "code",
    "outputId": "1935f2b7-2faa-4934-8afa-9ff53762c139",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
      "- path is now set to: {/content}\n"
     ]
    }
   ],
   "source": [
    "!kaggle config set -n path -v{/content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "oJ8dkPguXMHy",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "!chmod 600 /root/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBQeWn9jBbRn",
    "colab_type": "text"
   },
   "source": [
    "Add folders necessary for dividing test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "wgcJ4c9Kn-fi",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "!mkdir /content/pracaMgr/input/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "apkDtqobX2Je",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "!mkdir /content/pracaMgr/input/test_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "-dI2XnsrgRdy",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "!mkdir /content/pracaMgr/input/train_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kW4QmsyoBUX5",
    "colab_type": "text"
   },
   "source": [
    "Download data from Kaggle using following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "oFS0FOy2XRNg",
    "colab_type": "code",
    "outputId": "2c4d9cf7-41b1-45e1-cd83-8986725247d5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading sample_submission_v2.csv to /content/pracaMgr/input\n",
      "\r  0% 0.00/274k [00:00<?, ?B/s]\n",
      "100% 274k/274k [00:00<00:00, 40.7MB/s]\n",
      "Downloading train_ship_segmentations_v2.csv.zip to /content/pracaMgr/input\n",
      " 50% 9.00M/18.0M [00:01<00:01, 8.51MB/s]\n",
      "100% 18.0M/18.0M [00:01<00:00, 16.9MB/s]\n",
      "Downloading test_v2.zip to /content/pracaMgr/input\n",
      " 99% 2.11G/2.12G [00:47<00:00, 21.7MB/s]\n",
      "100% 2.12G/2.12G [00:47<00:00, 47.5MB/s]\n",
      "Downloading train_v2.zip to /content/pracaMgr/input\n",
      "100% 26.4G/26.4G [08:31<00:00, 70.2MB/s]\n",
      "100% 26.4G/26.4G [08:31<00:00, 55.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c airbus-ship-detection -p /content/pracaMgr/input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ziTVV8moBg7v",
    "colab_type": "text"
   },
   "source": [
    "Unpack all data to selected folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "yjMVPWxLaRRM",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile(\"/content/pracaMgr/input/train_ship_segmentations_v2.csv.zip\", 'r')\n",
    "zip_ref.extractall(\"/content/pracaMgr/input/\")\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "XMCh7K8qZuTV",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "zip_ref = zipfile.ZipFile(\"/content/pracaMgr/input/test_v2.zip\", 'r')\n",
    "zip_ref.extractall(\"/content/pracaMgr/input/test_v2\")\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "bQU-Ux4EaZuX",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "zip_ref = zipfile.ZipFile(\"/content/pracaMgr/input/train_v2.zip\", 'r')\n",
    "zip_ref.extractall(\"/content/pracaMgr/input/train_v2\")\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJcXjlf9Bj5j",
    "colab_type": "text"
   },
   "source": [
    "Move unnecessary zip folders to somewhere else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "VcjOz0Qga1bs",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "!mkdir /kaggle_zips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "a_2t4JMuauCl",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.rename(\"/content/pracaMgr/input/train_ship_segmentations_v2.csv.zip\", \"/kaggle_zips/train_ship_segmentations_v2.csv.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "XqdZWbWna69r",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "os.rename(\"/content/pracaMgr/input/train_v2.zip\", \"/kaggle_zips/train_v2.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "d9SaEo7ia6um",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "os.rename(\"/content/pracaMgr/input/test_v2.zip\", \"/kaggle_zips/test_v2.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce_9Ky5TBpbl",
    "colab_type": "text"
   },
   "source": [
    "Using RLE algorithm take some example data for creating Bounding Boxes for training purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "IVG5OLKlbv-f",
    "colab_type": "code",
    "outputId": "1a4f4813-009e-467a-a295-762867bf59a3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ships:  81723\n",
      "Going with full check\n",
      "Checked ships: 81723\n",
      "Incorrect ships: 1371\n",
      "Correct ships: 80352\n",
      "Incorrect to correct ratio: 0.01706242532855436\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "!python3 /content/pracaMgr/Decoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "3QbZF3hLBVE4",
    "colab_type": "code",
    "outputId": "777ac890-26d3-48c6-ac29-cdd4ac0c57dc",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images without ships: 150000\n",
      "Going with full check with 150000 images\n",
      "Checked images: 150000\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "!python3 /content/pracaMgr/Background_decoder.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4x8_LECB02c",
    "colab_type": "text"
   },
   "source": [
    "**Move it to the correct folder**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "0CFkLXY5sGBq",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "if os.path.exists(\"/content/entry_data.csv\"):\n",
    "  os.rename(\"/content/entry_data.csv\", \"/content/pracaMgr/entry_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7mQzb9nCGiI",
    "colab_type": "text"
   },
   "source": [
    "**Train stuff!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "1Fw7NV27HGK8",
    "colab_type": "code",
    "outputId": "6a69abd8-e926-4722-9146-afa3b306136d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Parsing annotation files\n",
      "Found class name with special name bg. Will be treated as a background region (this is usually for hard negative mining).\n",
      "Premature end of JPEG file\n",
      "Training images per class:\n",
      "{'bg': 150000, 'ship': 80352}\n",
      "Num classes (including bg) = 2\n",
      "Config has been written to config.pickle, and can be loaded when testing to ensure correct results\n",
      "Num train samples 160081\n",
      "Num val samples 0\n",
      "Num test samples 31893\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0707 10:55:10.518693 139908715136896 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0707 10:55:10.530035 139908715136896 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:508: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0707 10:55:10.554330 139908715136896 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3837: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0707 10:55:10.586759 139908715136896 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3661: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0707 10:55:11.861393 139908715136896 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3814: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W0707 10:55:11.903506 139908715136896 deprecation_wrapper.py:119] From /content/pracaMgr/keras_frcnn/RoiPoolingConv.py:108: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "W0707 10:55:13.288261 139908715136896 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3665: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "loading weights from resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "Could not load pretrained model weights. Weights can be found in the keras application folder         https://github.com/fchollet/keras/tree/master/keras/applications\n",
      "W0707 10:55:13.356428 139908715136896 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0707 10:55:13.367891 139908715136896 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3075: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0707 10:55:13.371187 139908715136896 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "2019-07-07 10:55:15.327780: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
      "2019-07-07 10:55:15.327985: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2a07dc0 executing computations on platform Host. Devices:\n",
      "2019-07-07 10:55:15.328015: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-07-07 10:55:15.345828: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
      "2019-07-07 10:55:15.589719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-07-07 10:55:15.590278: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2a09100 executing computations on platform CUDA. Devices:\n",
      "2019-07-07 10:55:15.590311: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2019-07-07 10:55:15.590560: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-07-07 10:55:15.590910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2019-07-07 10:55:15.600464: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-07-07 10:55:15.776286: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2019-07-07 10:55:15.851806: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "2019-07-07 10:55:15.869838: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "2019-07-07 10:55:16.041839: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2019-07-07 10:55:16.145494: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2019-07-07 10:55:16.478886: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-07-07 10:55:16.479185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-07-07 10:55:16.479716: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-07-07 10:55:16.480044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2019-07-07 10:55:16.480167: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-07-07 10:55:16.481766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-07-07 10:55:16.481800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2019-07-07 10:55:16.481812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2019-07-07 10:55:16.482201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-07-07 10:55:16.482625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-07-07 10:55:16.482964: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2019-07-07 10:55:16.483008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14202 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "W0707 10:55:18.189734 139908715136896 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:783: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "W0707 10:55:18.190183 139908715136896 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:786: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Starting training\n",
      "Epoch 1/40\n",
      "2019-07-07 10:55:26.710773: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-07-07 10:55:44.258683: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      " 735/1000 [=====================>........] - ETA: 2:43 - rpn_cls: 0.3913 - rpn_regr: 0.0860 - detector_cls: 0.0380 - detector_regr: 0.0778\n",
      "Average number of overlapping bounding boxes from RPN = 0.032 for 1000 previous iterations\n",
      "1000/1000 [==============================] - 610s 610ms/step - rpn_cls: 0.3623 - rpn_regr: 0.0855 - detector_cls: 0.0331 - detector_regr: 0.0703\n",
      "Mean number of bounding boxes from RPN overlapping ground truth boxes: 0.02714600146735143\n",
      "Classifier accuracy for bounding boxes from RPN: 0.99796875\n",
      "Loss RPN classifier: 0.26465176278498176\n",
      "Loss RPN regression: 0.08051383702643215\n",
      "Loss Detector classifier: 0.017730373498310855\n",
      "Loss Detector regression: 0.04412462106347084\n",
      "Elapsed time: 609.6625518798828\n",
      "Current loss value:  0.4070205943731956\n",
      "Total loss decreased from inf to 0.4070205943731956, saving weights\n",
      "File removing was not possible\n",
      "[Errno 2] No such file or directory: '/content/drive/My Drive/pracaMgr/Weights/weightsf.hdf5'\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/pracaMgr/train_frcnn.py\", line 354, in <module>\n",
      "    shutil.copy(path + \"/config.pickle\", \"/content/drive/My Drive/pracaMgr/Weights/config.pickle\")\n",
      "  File \"/usr/lib/python3.6/shutil.py\", line 245, in copy\n",
      "    copyfile(src, dst, follow_symlinks=follow_symlinks)\n",
      "  File \"/usr/lib/python3.6/shutil.py\", line 120, in copyfile\n",
      "    with open(src, 'rb') as fsrc:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/content/pracaMgr/input/config.pickle'\n"
     ]
    }
   ],
   "source": [
    "!python3 /content/pracaMgr/train_frcnn.py simple -p /content/pracaMgr/entry_data.csv --num_epochs=40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COn4zM43e0jD",
    "colab_type": "text"
   },
   "source": [
    "**For testing purposes, take the best weights from Google Drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "cozPMeSWxbtK",
    "colab_type": "code",
    "outputId": "1b1b01f6-fddb-4034-b7bb-4c4d19f4b3b6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/weights.hdf5'"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.copy(\"/content/drive/My Drive/pracaMgr/Weights/Best/1699_dp.hdf5\", \"/content/weights.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfH96GV8e481",
    "colab_type": "text"
   },
   "source": [
    "Pull any changes new changes, if it's necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "UQRIGQSgIO7J",
    "colab_type": "code",
    "outputId": "89489f1b-59a8-43e2-e053-fc76d2eb5755",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/pracaMgr\n",
      "remote: Enumerating objects: 5, done.\u001b[K\n",
      "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
      "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (3/3), done.\n",
      "From https://github.com/zakrzewki/pracaMgr\n",
      "   868f7f9..77af64f  master     -> origin/master\n",
      "Updating 868f7f9..77af64f\n",
      "Fast-forward\n",
      " test_frcnn.py | 6 \u001b[32m+++\u001b[m\u001b[31m---\u001b[m\n",
      " 1 file changed, 3 insertions(+), 3 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "%cd /content/pracaMgr\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Re1RYZKjCjWc",
    "colab_type": "text"
   },
   "source": [
    "**Test it, how it's working**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code",
    "id": "qHHx89y4fAYt",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "!python3 /content/pracaMgr/test_frcnn.py --p /content/pracaMgr/input/test_v2/ --input_weight_path /content/weights.hdf5 --config_filename /content/config.pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cq3eYE2WLA5b",
    "colab_type": "text"
   },
   "source": [
    "**Export results to Google Drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "6DkWXjXoLDMX",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "shutil.move(\"/content/results.csv\", \"content/gdrive/My Drive/pracaMgr/Weights/results.csv\")\n",
    "shutil.move(\"/content/ship_detected.csv\", \"content/gdrive/My Drive/pracaMgr/Weights/ship_detected.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Mgr.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
